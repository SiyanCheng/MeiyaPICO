{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于AlexNet的试纸识别模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    程思衍 siyanc@usc.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本模型输入的训练数据为试纸图片及其对应属性（阴性、阳性及隐性），在训练过后可以识别试纸属性。\n",
    "\n",
    "模型上应用深度学习** 卷积神经网络 **架构，基于Hinton及其学生Alex Krizhevsky[1]在2012年ImageNet竞赛中所夺魁的AlexNet构建训练架构，以达到对小范围内的物体进行卷积识别。\n",
    "\n",
    "我们将逐步介绍代码结构。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.引入所需要的包并将训练环境设为GPU环境"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本模型应用像素大小为（224，224）的黑白图片作为输入，经过多层卷积池化，故参数级别为1e+10，建议采用云或本地GPU环境进行训练。\n",
    "\n",
    "我们首先如下导入所需要的包/库，并将keras环境设置为GPU环境。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "from keras import metrics\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D\n",
    "from keras.initializers import he_normal\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "%matplotlib inline\n",
    "K.set_image_dim_ordering('th')\n",
    "\n",
    "#setting GPU\n",
    "config = tf.ConfigProto( device_count = {'GPU': 1 , 'CPU': 8} )\n",
    "sess = tf.Session(config=config)\n",
    "K.set_session(sess)\n",
    "print ('Using GPU for Computing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.读取图片"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "随后我们读取图片作为输入数据。\n",
    "\n",
    "训练数据应当放置在源代码同一路径下，并分别命名为0，1，2。\n",
    "\n",
    "在0文件夹中放置显隐性的试纸图片，在1文件夹中放置阴性（一条杠）试纸图片，在2文件夹中放置显阳性（两条杠）的试纸图片。\n",
    "\n",
    "读取同时我们将图片转换为（224，224）像素的统一大小并统一转换为黑白图片以便训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read images from folders\n",
    "images = []\n",
    "#labels = [] \n",
    "images_stat = []\n",
    "\n",
    "##############################################################\n",
    "#here we have 3 labels. The folders are named as 0/1/2, images\n",
    "#that have the same labels locate in same folder.\n",
    "#We read images and their labels below and resize them to \n",
    "#(224, 224) for future computation.\n",
    "##############################################################\n",
    "for folder in ['./0/','./1/','./2/']:\n",
    "    images_stat.append(len(os.listdir(folder)))\n",
    "    for image_name in os.listdir(folder):\n",
    "        image = cv2.imread(os.path.join(folder,image_name), cv2.IMREAD_GRAYSCALE)\n",
    "        if image is not None:\n",
    "            images.append(cv2.resize(image, (224, 224),interpolation=cv2.INTER_NEAREST))\n",
    "            #labels.append(folder.split('/')[1])\n",
    "\n",
    "#Plot one of the images\n",
    "images = np.array(images).reshape(images.shape[0], 224, 224)\n",
    "plt.imshow(images[15], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.分离数据并生成标签"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "按照上面代码的顺序，我们首先读入的是0文件夹中的文件，然后是1中的文件，最后才是2中文件。\n",
    "\n",
    "images_stat的作用的便是记录各个文件夹中包含多少个文件，并以此为依据分离数据并生成标签。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshapa data and generate their label\n",
    "images = np.array(images).reshape(images.shape[0], 1, 224, 224)\n",
    "data0 = images[0:images_stat[0]]\n",
    "label0 = np.zeros((data0.shape[0],))\n",
    "\n",
    "data1 = images[images_stat[0]:images_stat[0]+images_stat[1]]\n",
    "label1 = np.zeros((data1.shape[0],))+1\n",
    "\n",
    "data2 = images[images_stat[0]+images_stat[1]:]\n",
    "label2 = np.zeros((data2.shape[0],))+2\n",
    "\n",
    "images.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 扩张训练数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们应用keras内建的ImageDataGernertor对训练数据进行扩张。\n",
    "\n",
    "在本报告撰写的同时，本模型只有少量数据可供训练，为保证模型鲁棒性，在这里将数据规模扩张。若后续能够有更多的数据，则可以考虑删去该部分或是将变换系数减小。\n",
    "\n",
    "该接口会随机将图片进行旋转、上下平移、左右平移、放大、镜像放置。\n",
    "\n",
    "在这边我们将每张图片变换为500张，由底下的iteration_time声明，并将图片分别保存至auged_0/auged_1/auged_2文件夹中以供查看。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=90,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        cval=0,\n",
    "        vertical_flip=False)\n",
    "# fit parameters from data\n",
    "datagen.fit(images)\n",
    "# configure batch size and retrieve one batch of images\n",
    "iteration_time = 500\n",
    "\n",
    "os.makedirs('auged_0')\n",
    "data0_aug = np.array([])\n",
    "\n",
    "i = 0\n",
    "for X_batch, y_batch in datagen.flow(data0, label0, batch_size=data0.shape[0], save_to_dir='auged_0', save_prefix='aug', save_format='png'):\n",
    "    print (i)\n",
    "    if i >= iteration_time:\n",
    "        break\n",
    "    if len(data0_aug) == 0:\n",
    "        data0_aug = X_batch\n",
    "    else:\n",
    "        data0_aug = np.vstack((data0_aug, X_batch))\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('auged_1')\n",
    "data1_aug = np.array([])\n",
    "\n",
    "i = 0\n",
    "for X_batch, y_batch in datagen.flow(data1, label1, batch_size=data1.shape[0], save_to_dir='auged_1', save_prefix='aug', save_format='png'):\n",
    "    print (i)\n",
    "    if i >= iteration_time:\n",
    "        break\n",
    "    if len(data1_aug) == 0:\n",
    "        data1_aug = X_batch\n",
    "    else:\n",
    "        data1_aug = np.vstack((data1_aug, X_batch))\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('auged_2')\n",
    "data2_aug = np.array([])\n",
    "\n",
    "i = 0\n",
    "for X_batch, y_batch in datagen.flow(data2, label2, batch_size=data2.shape[0], save_to_dir='auged_2', save_prefix='aug', save_format='png'):\n",
    "    print(i)\n",
    "    if i >= iteration_time:\n",
    "        break\n",
    "    if len(data2_aug) == 0:\n",
    "        data2_aug = X_batch\n",
    "    else:\n",
    "        data2_aug = np.vstack((data2_aug, X_batch))\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.数据综合预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "至此，我们已拥有足量的训练数据及标签，在本代码块中我们首先拼接之前逐类扩张过的数据。\n",
    "\n",
    "随后将训练数据保存至data.npy文件中，研究人员可以随时读取以加快效率。\n",
    "\n",
    "紧接着我们将数据随机打乱以求客观性。\n",
    "\n",
    "最后我们将这些数据分为训练数据和测试数据，训练数据占75%，测试数据占25%。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_OF_CLASSES = 3\n",
    "\n",
    "#Concatenate data and labels\n",
    "auged_labels = np.vstack((np.zeros((data0.shape[0]*(iteration_time+1),1)), np.zeros((data1.shape[0]*(iteration_time+1),1))+1,\\\n",
    "                          np.zeros((data2.shape[0]*(iteration_time+1),1))+2))\n",
    "auged_labels = auged_labels.reshape((auged_labels.shape[0],))\n",
    "auged_data = np.vstack((data0, data0_aug, data1, data1_aug,data2, data2_aug))\n",
    "\n",
    "#save data, so you can resume and load data from here to continue the experiment.\n",
    "np.save('data.npy',auged_data)\n",
    "\n",
    "#shuffle data for objectivity\n",
    "rd_idx = [i for i in range(len(auged_data))]\n",
    "np.random.shuffle(rd_idx)\n",
    "\n",
    "shuffled_data = auged_data[rd_idx]\n",
    "shuffled_labels = auged_labels[rd_idx]\n",
    "\n",
    "#normalize data\n",
    "normalized_data = shuffled_data/255\n",
    "\n",
    "#train and test split for 0.75-0.25\n",
    "X_train, X_test, y_train, y_test = train_test_split(normalized_data, shuffled_labels, test_size=0.25, random_state=42)\n",
    "\n",
    "print (X_train.shape)\n",
    "print (X_test.shape)\n",
    "\n",
    "#make labels categorical\n",
    "Y_train = np_utils.to_categorical(y_train, NUMBER_OF_CLASSES)\n",
    "Y_test = np_utils.to_categorical(y_test, NUMBER_OF_CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 模型具体架构"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](Arch.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型应用Keras贯序接口构建，详细信息请查询[Keras API](http://keras-cn.readthedocs.io/en/latest/)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型架构为：\n",
    "\n",
    "> * 拥有96个卷积核，卷积核大小为（11，11），步长为4，激活函数为“relu”的卷积层\n",
    "> * 池化窗口为（3，3），步长为（2，2）的最大池化层\n",
    "\n",
    "> * 拥有96个卷积核，卷积核大小为（11，11），步长为4，激活函数为“relu”的卷积层\n",
    "> * 池化窗口为（3，3），步长为（2，2）的最大池化层\n",
    "\n",
    "> * 拥有384个卷积核，卷积核大小为（3，3），步长为1，激活函数为“relu”的卷积层\n",
    "> * 拥有384个卷积核，卷积核大小为（3，3），步长为1，激活函数为“relu”的卷积层\n",
    "> * 拥有256个卷积核，卷积核大小为（3，3），步长为1，激活函数为“relu”的卷积层\n",
    "> * 池化窗口为（3，3），步长为（2，2）的最大池化层\n",
    "\n",
    "> * 拥有4096个神经元，激活函数为“relu”的全连接层\n",
    "> * 拥有4096个神经元，激活函数为“relu”的全连接层\n",
    "> * 拥有3个神经元，激活函数为“softmax”的输出层\n",
    "\n",
    "该卷积神经网络架构在2012年ImageNet比赛中成名，并带动整个深度学习领域的发展，这边是我们在该问题中使用AlexNet的原因。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training\n",
    "model = Sequential()\n",
    "\n",
    "## Architecture\n",
    "model.add(Conv2D( filters = 96, kernel_size = (11,11), strides = 4, padding = 'same', activation = 'relu', input_shape = (1, 224, 224), kernel_initializer = 'he_normal'))\n",
    "model.add(MaxPooling2D( pool_size = (3,3), strides = (2,2), padding= 'same', data_format = None)) # overlapping pooling\n",
    "\n",
    "model.add(Conv2D( filters = 256, kernel_size = (5,5), strides = 1, padding = 'same', activation = 'relu', kernel_initializer = 'he_normal'))\n",
    "model.add(MaxPooling2D( pool_size = (3,3), strides = (2,2), padding= 'same', data_format = None)) \n",
    "\n",
    "model.add(Conv2D( filters = 384, kernel_size = (3,3), strides = 1, padding = 'same', activation = 'relu', kernel_initializer = 'he_normal'))\n",
    "model.add(Conv2D( filters = 384, kernel_size = (3,3), strides = 1, padding = 'same', activation = 'relu', kernel_initializer = 'he_normal'))\n",
    "model.add(Conv2D( filters = 256, kernel_size = (3,3), strides = 1, padding = 'same', activation = 'relu', kernel_initializer = 'he_normal'))\n",
    "model.add(MaxPooling2D( pool_size = (3,3), strides = (2,2), padding= 'same', data_format = None))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense( units = 4096, activation = 'relu'))\n",
    "model.add(Dense( units = 4096, activation = 'relu'))\n",
    "\n",
    "model.add(Dense( units = 3, activation = 'softmax'))\n",
    "model.summary()\n",
    "\n",
    "## Optimizer\n",
    "adam = optimizers.adam(lr=0.00005, beta_1 = 0.9, beta_2 = 0.999, epsilon = None, decay= 0, amsgrad = False)\n",
    "momentum = optimizers.SGD(lr=0.01, momentum = 0.9, decay=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile and trian\n",
    "model.compile(optimizer = adam, loss = categorical_crossentropy, metrics=[metrics.categorical_accuracy])\n",
    "model.fit(X_train, Y_train, batch_size = 32, epochs = 10, validation_data=(X_test, Y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
